{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-intro",
   "metadata": {},
   "source": [
    "# Neural Network Development Tutorial: Wafer Defect Classification\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates the progressive development of classification models for wafer defect detection, starting from traditional machine learning methods and advancing to deep neural networks.\n",
    "\n",
    "## Learning Objectives\n",
    "- Compare traditional ML (Random Forest, SVM) with neural networks\n",
    "- Understand when spatial structure matters\n",
    "- Build progressively complex neural architectures\n",
    "- Apply transfer learning for improved performance\n",
    "\n",
    "## Dataset\n",
    "The WM-811K wafer map dataset contains grayscale images (26√ó26 pixels) of semiconductor wafers with 38 different defect types.\n",
    "\n",
    "## Tutorial Structure\n",
    "1. **Traditional ML**: Random Forest and Support Vector Machine\n",
    "2. **Simple NN**: Single-layer neural network\n",
    "3. **MLP**: Multi-layer perceptron with activation functions\n",
    "4. **CNN**: Convolutional neural network\n",
    "5. **Transfer Learning**: Pre-trained ResNet18\n",
    "6. **Comparison**: Comprehensive performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part0-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 0: Setup and Data Loading\n",
    "\n",
    "First, we'll import the necessary libraries and load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Traditional ML models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# PyTorch for neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load your wafer defect dataset. Adjust the file path as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load your data - adjust path as needed\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming you have X (images) and y (labels)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example format:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Placeholder - replace with your actual data loading\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData shape: X=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m√ó\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Load your data - adjust path as needed\n",
    "# Assuming you have X (images) and y (labels)\n",
    "# Example format:\n",
    "# X shape: (n_samples, 26, 26) - grayscale images\n",
    "# y shape: (n_samples,) - defect type labels\n",
    "\n",
    "# If you have a pickle or npz file:\n",
    "data = np.load('wafer_data.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# For this tutorial, let's assume you've loaded:\n",
    "# X: your wafer images\n",
    "# y: your labels\n",
    "\n",
    "# Placeholder - replace with your actual data loading\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Image dimensions: {X.shape[1]}√ó{X.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = np.random.randint(0, len(X))\n",
    "    ax.imshow(X[idx], cmap='gray')\n",
    "    ax.set_title(f'Class: {y[idx]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Wafer Defect Images')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encode-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels if they're not already numeric\n",
    "if y.dtype == 'object' or not np.issubdtype(y.dtype, np.integer):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    print(f\"Encoded {len(label_encoder.classes_)} classes\")\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "print(f\"Total classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "# First split: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 75% train, 25% val (of the 80%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalize",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "\n",
    "Normalize pixel values to [0, 1] range for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to [0, 1]\n",
    "X_train_norm = X_train.astype('float32') / 255.0\n",
    "X_val_norm = X_val.astype('float32') / 255.0\n",
    "X_test_norm = X_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Normalized data range: [{X_train_norm.min():.2f}, {X_train_norm.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Traditional Machine Learning Methods\n",
    "\n",
    "Before diving into neural networks, let's establish baselines using traditional machine learning methods: **Random Forest** and **Support Vector Machine**.\n",
    "\n",
    "## Why Start Here?\n",
    "- **Fast training**: Traditional ML models train much faster\n",
    "- **Strong baselines**: Often perform surprisingly well\n",
    "- **No spatial structure**: These models flatten images, losing spatial information\n",
    "- **Feature engineering**: Work with raw pixel values\n",
    "\n",
    "## Key Limitation\n",
    "Both models require flattening the 26√ó26 images into 676-dimensional vectors, **losing the 2D spatial structure** that CNNs can exploit.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 Random Forest Classifier\n",
    "\n",
    "Random Forest builds an ensemble of decision trees, each trained on a random subset of data and features.\n",
    "\n",
    "**Advantages:**\n",
    "- Handles non-linear relationships\n",
    "- Robust to overfitting with many trees\n",
    "- No extensive hyperparameter tuning needed\n",
    "- Built-in feature importance\n",
    "\n",
    "**Disadvantages:**\n",
    "- Treats pixels as independent features\n",
    "- Doesn't capture spatial patterns\n",
    "- Can be memory-intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-prepare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images for traditional ML\n",
    "X_train_flat = X_train_norm.reshape(X_train_norm.shape[0], -1)\n",
    "X_val_flat = X_val_norm.reshape(X_val_norm.shape[0], -1)\n",
    "X_test_flat = X_test_norm.reshape(X_test_norm.shape[0], -1)\n",
    "\n",
    "print(f\"Flattened shape: {X_train_flat.shape}\")\n",
    "print(f\"Each image is now a {X_train_flat.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest Classifier...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Create Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=20,          # Maximum depth of trees\n",
    "    min_samples_split=10,  # Minimum samples to split a node\n",
    "    min_samples_leaf=4,    # Minimum samples in a leaf\n",
    "    random_state=42,\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_flat, y_train)\n",
    "\n",
    "print(\"\\nRandom Forest training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_train_pred = rf_model.predict(X_train_flat)\n",
    "rf_val_pred = rf_model.predict(X_val_flat)\n",
    "rf_test_pred = rf_model.predict(X_test_flat)\n",
    "\n",
    "rf_train_acc = accuracy_score(y_train, rf_train_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_val_pred)\n",
    "rf_test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Random Forest Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy:   {rf_train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {rf_val_acc:.4f}\")\n",
    "print(f\"Test Accuracy:       {rf_test_acc:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show classification report\n",
    "print(\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, rf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top important pixels\n",
    "feature_importance = rf_model.feature_importances_\n",
    "importance_map = feature_importance.reshape(26, 26)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(importance_map, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Feature Importance')\n",
    "plt.title('Random Forest: Pixel Importance Map')\n",
    "plt.xlabel('Pixel X')\n",
    "plt.ylabel('Pixel Y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: Brighter areas indicate pixels that are more important for classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svm-title",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Support Vector Machine (SVM)\n",
    "\n",
    "SVM finds an optimal hyperplane that separates different classes in high-dimensional space.\n",
    "\n",
    "**Advantages:**\n",
    "- Effective in high-dimensional spaces\n",
    "- Memory efficient (uses support vectors)\n",
    "- Kernel trick allows non-linear decision boundaries\n",
    "\n",
    "**Disadvantages:**\n",
    "- Can be slow to train on large datasets\n",
    "- Sensitive to feature scaling\n",
    "- Requires careful kernel selection\n",
    "\n",
    "**Note:** We'll use a linear kernel for speed. RBF kernel would be more powerful but much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svm-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Support Vector Machine...\")\n",
    "print(\"Using linear kernel for faster training...\\n\")\n",
    "\n",
    "# Create SVM model with linear kernel\n",
    "svm_model = SVC(\n",
    "    kernel='linear',\n",
    "    C=1.0,              # Regularization parameter\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    max_iter=1000       # Maximum iterations\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_flat, y_train)\n",
    "\n",
    "print(\"\\nSVM training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svm-evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SVM\n",
    "svm_train_pred = svm_model.predict(X_train_flat)\n",
    "svm_val_pred = svm_model.predict(X_val_flat)\n",
    "svm_test_pred = svm_model.predict(X_test_flat)\n",
    "\n",
    "svm_train_acc = accuracy_score(y_train, svm_train_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_val_pred)\n",
    "svm_test_acc = accuracy_score(y_test, svm_test_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Support Vector Machine Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy:   {svm_train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {svm_val_acc:.4f}\")\n",
    "print(f\"Test Accuracy:       {svm_test_acc:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show classification report\n",
    "print(\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, svm_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-ml-comparison",
   "metadata": {},
   "source": [
    "---\n",
    "## Traditional ML Comparison\n",
    "\n",
    "Let's compare Random Forest and SVM performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-comparison-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare traditional ML models\n",
    "models = ['Random Forest', 'SVM (Linear)']\n",
    "train_accs = [rf_train_acc, svm_train_acc]\n",
    "val_accs = [rf_val_acc, svm_val_acc]\n",
    "test_accs = [rf_test_acc, svm_test_acc]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - width, train_accs, width, label='Train', alpha=0.8)\n",
    "ax.bar(x, val_accs, width, label='Validation', alpha=0.8)\n",
    "ax.bar(x + width, test_accs, width, label='Test', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Traditional ML Methods: Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (train, val, test) in enumerate(zip(train_accs, val_accs, test_accs)):\n",
    "    ax.text(i - width, train + 0.02, f'{train:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i, val + 0.02, f'{val:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + width, test + 0.02, f'{test:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-insights",
   "metadata": {},
   "source": [
    "## üîç Key Insights: Traditional ML\n",
    "\n",
    "### What We Learned:\n",
    "1. **Random Forest** typically performs better than linear SVM for this task\n",
    "2. Both models provide **strong baselines** without complex tuning\n",
    "3. Training is **fast** compared to neural networks\n",
    "4. **Limitation**: Both flatten images, losing spatial structure\n",
    "\n",
    "### Why Neural Networks?\n",
    "While traditional ML works, it treats each pixel independently. Neural networks (especially CNNs) can:\n",
    "- Learn spatial patterns (edges, shapes, textures)\n",
    "- Build hierarchical features automatically\n",
    "- Potentially achieve higher accuracy\n",
    "\n",
    "Let's see if neural networks can beat these baselines!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Simple Single-Layer Neural Network\n",
    "\n",
    "Now let's build our first neural network - a simple single-layer model that's essentially **logistic regression**.\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input (26√ó26=676) ‚Üí Flatten ‚Üí Linear(676‚Üí38) ‚Üí Output\n",
    "```\n",
    "\n",
    "This is the simplest possible neural network:\n",
    "- **No hidden layers**\n",
    "- **No activation functions** (linear transformation only)\n",
    "- Just learns a direct mapping from pixels to classes\n",
    "\n",
    "## What We'll Learn:\n",
    "- How to structure a basic PyTorch model\n",
    "- Training loop implementation\n",
    "- Why deeper networks are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-nn-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Single-layer neural network (logistic regression)\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Apply linear transformation\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "input_size = 26 * 26  # 676 pixels\n",
    "simple_model = SimpleNN(input_size, n_classes).to(device)\n",
    "\n",
    "# Count parameters\n",
    "simple_params = sum(p.numel() for p in simple_model.parameters())\n",
    "print(f\"Model: Simple Single-Layer NN\")\n",
    "print(f\"Total parameters: {simple_params:,}\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-utils",
   "metadata": {},
   "source": [
    "## Training Utilities\n",
    "\n",
    "Let's create helper functions for training and evaluation that we'll reuse for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on a dataset\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Training utilities defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-dataloaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare PyTorch data loaders\n",
    "batch_size = 64\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_norm).unsqueeze(1)  # Add channel dimension\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val_norm).unsqueeze(1)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test_norm).unsqueeze(1)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-simple-nn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training Simple Single-Layer NN...\\n\")\n",
    "simple_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(simple_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(simple_model, val_loader, criterion, device)\n",
    "    \n",
    "    simple_history['train_loss'].append(train_loss)\n",
    "    simple_history['train_acc'].append(train_acc)\n",
    "    simple_history['val_loss'].append(val_loss)\n",
    "    simple_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_acc = evaluate(simple_model, test_loader, criterion, device)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-simple-nn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(simple_history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(simple_history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Simple NN: Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(simple_history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(simple_history['val_acc'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Simple NN: Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-insights",
   "metadata": {},
   "source": [
    "## üîç Key Insights: Simple Neural Network\n",
    "\n",
    "### Observations:\n",
    "1. **Linear model**: No activation functions = just weighted sum\n",
    "2. **Limited capacity**: Can't learn complex non-linear patterns\n",
    "3. **Similar to SVM**: Both are linear classifiers\n",
    "4. **Fast training**: Fewer parameters means quick convergence\n",
    "\n",
    "### Why It's Limited:\n",
    "- No hidden layers to learn intermediate features\n",
    "- Can't capture non-linear relationships in data\n",
    "- Treats problem as linearly separable\n",
    "\n",
    "**Next step**: Add hidden layers and non-linear activations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Now we'll add **hidden layers** and **activation functions** to learn non-linear patterns.\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input (676) ‚Üí FC(512) ‚Üí ReLU ‚Üí Dropout \n",
    "           ‚Üí FC(256) ‚Üí ReLU ‚Üí Dropout\n",
    "           ‚Üí FC(128) ‚Üí ReLU ‚Üí Dropout\n",
    "           ‚Üí FC(38) ‚Üí Output\n",
    "```\n",
    "\n",
    "## New Components:\n",
    "1. **Hidden Layers**: Learn intermediate representations\n",
    "2. **ReLU Activation**: Introduces non-linearity (max(0, x))\n",
    "3. **Dropout**: Prevents overfitting by randomly dropping neurons\n",
    "\n",
    "This should perform better than the simple model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlp-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron with dropout\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Hidden layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Hidden layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Hidden layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "mlp_model = MLP(input_size, n_classes).to(device)\n",
    "\n",
    "mlp_params = sum(p.numel() for p in mlp_model.parameters())\n",
    "print(f\"Model: Multi-Layer Perceptron\")\n",
    "print(f\"Total parameters: {mlp_params:,}\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-mlp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training Multi-Layer Perceptron...\\n\")\n",
    "mlp_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(mlp_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(mlp_model, val_loader, criterion, device)\n",
    "    \n",
    "    mlp_history['train_loss'].append(train_loss)\n",
    "    mlp_history['train_acc'].append(train_acc)\n",
    "    mlp_history['val_loss'].append(val_loss)\n",
    "    mlp_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_acc = evaluate(mlp_model, test_loader, criterion, device)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-mlp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(mlp_history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(mlp_history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('MLP: Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(mlp_history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(mlp_history['val_acc'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('MLP: Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mlp-insights",
   "metadata": {},
   "source": [
    "## üîç Key Insights: Multi-Layer Perceptron\n",
    "\n",
    "### Improvements:\n",
    "1. **Non-linear learning**: ReLU enables complex pattern recognition\n",
    "2. **Better accuracy**: Should outperform simple NN and possibly RF/SVM\n",
    "3. **Dropout helps**: Prevents overfitting on training data\n",
    "\n",
    "### Still Limited:\n",
    "- **No spatial awareness**: Still flattens images\n",
    "- **Loses structure**: Doesn't know which pixels are neighbors\n",
    "- **Not translation-invariant**: Can't recognize patterns regardless of position\n",
    "\n",
    "**Solution**: Use Convolutional Neural Networks (CNNs)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Convolutional Neural Network (CNN)\n",
    "\n",
    "Now we'll use **convolutional layers** to preserve and learn from the 2D spatial structure of images.\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input (1√ó26√ó26)\n",
    "  ‚Üì Conv(16) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "  ‚Üì Conv(32) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "  ‚Üì Conv(64) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "  ‚Üì Flatten\n",
    "  ‚Üì FC(128) ‚Üí ReLU ‚Üí Dropout\n",
    "  ‚Üì FC(38) ‚Üí Output\n",
    "```\n",
    "\n",
    "## Why CNNs Excel:\n",
    "1. **Spatial awareness**: Learns from local pixel neighborhoods\n",
    "2. **Translation invariance**: Recognizes patterns anywhere in the image\n",
    "3. **Hierarchical features**: Early layers detect edges, later layers detect complex shapes\n",
    "4. **Parameter efficiency**: Shared weights across spatial locations\n",
    "\n",
    "This is your original architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnn-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network for wafer defect classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional block 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional block 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional block 3\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)  # 26√ó26 ‚Üí 13√ó13\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)  # 13√ó13 ‚Üí 6√ó6\n",
    "        \n",
    "        # Conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool3(x)  # 6√ó6 ‚Üí 3√ó3\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # FC layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "cnn_model = CNN(n_classes).to(device)\n",
    "\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "print(f\"Model: Convolutional Neural Network\")\n",
    "print(f\"Total parameters: {cnn_params:,}\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-cnn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 40\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training Convolutional Neural Network...\\n\")\n",
    "cnn_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(cnn_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(cnn_model, val_loader, criterion, device)\n",
    "    \n",
    "    cnn_history['train_loss'].append(train_loss)\n",
    "    cnn_history['train_acc'].append(train_acc)\n",
    "    cnn_history['val_loss'].append(val_loss)\n",
    "    cnn_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(cnn_model.state_dict(), '/home/claude/best_cnn_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "cnn_model.load_state_dict(torch.load('/home/claude/best_cnn_model.pth'))\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_acc = evaluate(cnn_model, test_loader, criterion, device)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-cnn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(cnn_history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(cnn_history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('CNN: Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(cnn_history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(cnn_history['val_acc'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('CNN: Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cnn-insights",
   "metadata": {},
   "source": [
    "## üîç Key Insights: CNN\n",
    "\n",
    "### Why CNNs Work Better:\n",
    "1. **Spatial feature learning**: Convolutions detect edges, textures, patterns\n",
    "2. **Translation invariance**: Same filter applied across entire image\n",
    "3. **Hierarchical features**: Early layers ‚Üí simple features, Deep layers ‚Üí complex patterns\n",
    "4. **Parameter efficiency**: Fewer parameters than MLP, but more powerful\n",
    "\n",
    "### Expected Results:\n",
    "- **Higher accuracy** than MLP and traditional ML\n",
    "- **Better generalization** due to spatial inductive biases\n",
    "- **Learned features** are interpretable (can visualize filters)\n",
    "\n",
    "**Can we do even better?** Yes - with transfer learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Transfer Learning with ResNet18\n",
    "\n",
    "Transfer learning uses a model **pre-trained on millions of images** (ImageNet) and adapts it to our task.\n",
    "\n",
    "## Why Transfer Learning?\n",
    "1. **Pre-learned features**: ResNet already knows edges, textures, shapes\n",
    "2. **Less data needed**: Can work well even with smaller datasets\n",
    "3. **Faster convergence**: Starts from good feature representations\n",
    "4. **Better generalization**: Learned robust features from diverse images\n",
    "\n",
    "## Architecture:\n",
    "- Use **ResNet18** (18-layer deep network)\n",
    "- Modify first layer: ImageNet expects RGB (3 channels), we have grayscale (1 channel)\n",
    "- Replace final layer: ImageNet has 1000 classes, we have 38\n",
    "- **Fine-tuning**: Train entire network with lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resnet-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify first conv layer for grayscale input (1 channel instead of 3)\n",
    "resnet_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Replace final fully connected layer\n",
    "num_features = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_features, n_classes)\n",
    "\n",
    "# Move to device\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "resnet_params = sum(p.numel() for p in resnet_model.parameters())\n",
    "print(f\"Model: ResNet18 (Transfer Learning)\")\n",
    "print(f\"Total parameters: {resnet_params:,}\")\n",
    "print(f\"\\nModifications:\")\n",
    "print(f\"- First layer: Conv2d(1, 64) for grayscale\")\n",
    "print(f\"- Final layer: Linear({num_features}, {n_classes})\")\n",
    "print(f\"- Pre-trained on ImageNet: ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-resnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration for transfer learning\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0001  # Lower LR for fine-tuning\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# Training loop\n",
    "print(\"Training ResNet18 with Transfer Learning...\\n\")\n",
    "resnet_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(resnet_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(resnet_model, val_loader, criterion, device)\n",
    "    \n",
    "    resnet_history['train_loss'].append(train_loss)\n",
    "    resnet_history['train_acc'].append(train_acc)\n",
    "    resnet_history['val_loss'].append(val_loss)\n",
    "    resnet_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(resnet_model.state_dict(), '/home/claude/best_resnet_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "resnet_model.load_state_dict(torch.load('/home/claude/best_resnet_model.pth'))\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_acc = evaluate(resnet_model, test_loader, criterion, device)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-resnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(resnet_history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(resnet_history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('ResNet18: Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(resnet_history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(resnet_history['val_acc'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('ResNet18: Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resnet-insights",
   "metadata": {},
   "source": [
    "## üîç Key Insights: Transfer Learning\n",
    "\n",
    "### Advantages:\n",
    "1. **Knowledge transfer**: Leverages features learned from millions of images\n",
    "2. **Deeper network**: 18 layers vs. 3 in our custom CNN\n",
    "3. **Residual connections**: Helps gradient flow, enables deeper networks\n",
    "4. **Proven architecture**: ResNet won ImageNet competition\n",
    "\n",
    "### Expected Results:\n",
    "- **Highest accuracy** among all models\n",
    "- **Faster convergence** than training from scratch\n",
    "- **Better generalization** even with limited data\n",
    "\n",
    "### Trade-offs:\n",
    "- More parameters (11M+ vs 300K for custom CNN)\n",
    "- Slower inference time\n",
    "- Higher memory requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Complete Model Comparison\n",
    "\n",
    "Let's compare all models we've trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "models_list = [\n",
    "    'Random Forest',\n",
    "    'SVM (Linear)',\n",
    "    'Simple NN',\n",
    "    'MLP',\n",
    "    'CNN',\n",
    "    'ResNet18'\n",
    "]\n",
    "\n",
    "# You'll need to fill in the actual test accuracies from your runs\n",
    "test_accuracies = [\n",
    "    rf_test_acc,\n",
    "    svm_test_acc,\n",
    "    # Add other test accuracies as you complete training\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "    rf_model.n_estimators * 1000,  # Approximate\n",
    "    0,  # SVM support vectors vary\n",
    "    simple_params,\n",
    "    mlp_params,\n",
    "    cnn_params,\n",
    "    resnet_params\n",
    "]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models_list,\n",
    "    'Parameters': parameters,\n",
    "    'Test Accuracy': test_accuracies\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DFE6E9']\n",
    "bars = ax1.bar(models_list, test_accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_ylabel('Test Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticklabels(models_list, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, test_accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Parameter comparison (log scale)\n",
    "param_labels = [f\"{p/1e6:.2f}M\" if p > 1e6 else f\"{p/1e3:.1f}K\" for p in parameters]\n",
    "bars2 = ax2.bar(models_list, parameters, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylabel('Number of Parameters', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Model Complexity Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_xticklabels(models_list, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, label in zip(bars2, param_labels):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height * 1.1,\n",
    "            label, ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-insights",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ Final Insights and Recommendations\n",
    "\n",
    "## Model Progression Summary\n",
    "\n",
    "### 1. Traditional ML (Random Forest, SVM)\n",
    "- ‚úÖ **Fast training**, strong baselines\n",
    "- ‚ùå **Lose spatial structure** (flatten images)\n",
    "- üìä Good starting point for understanding data\n",
    "\n",
    "### 2. Simple Neural Network\n",
    "- ‚úÖ **Simple to understand**, fast to train\n",
    "- ‚ùå **Linear only**, can't learn complex patterns\n",
    "- üìä Similar performance to linear SVM\n",
    "\n",
    "### 3. Multi-Layer Perceptron (MLP)\n",
    "- ‚úÖ **Non-linear learning**, better than simple NN\n",
    "- ‚ùå **Still flattens images**, no spatial awareness\n",
    "- üìä Moderate improvement over simple models\n",
    "\n",
    "### 4. Convolutional Neural Network (CNN)\n",
    "- ‚úÖ **Spatial feature learning**, translation invariant\n",
    "- ‚úÖ **Efficient parameters**, good accuracy\n",
    "- üìä Significant improvement - best custom architecture\n",
    "\n",
    "### 5. Transfer Learning (ResNet18)\n",
    "- ‚úÖ **Pre-trained features**, deepest network\n",
    "- ‚úÖ **Highest accuracy**, best generalization\n",
    "- ‚ö†Ô∏è **More parameters**, slower inference\n",
    "- üìä Best overall performance\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Recommendations\n",
    "\n",
    "### For Production:\n",
    "1. **High accuracy required**: Use **ResNet18** transfer learning\n",
    "2. **Speed/resource constrained**: Use **Custom CNN** or **Random Forest**\n",
    "3. **Quick baseline**: Start with **Random Forest**\n",
    "\n",
    "### For Further Improvement:\n",
    "1. **Data augmentation**: Rotation, flipping, noise\n",
    "2. **Ensemble methods**: Combine multiple models\n",
    "3. **Architecture search**: Try other pre-trained models (ResNet50, EfficientNet)\n",
    "4. **Hyperparameter tuning**: Learning rate, dropout, batch size\n",
    "5. **Class balancing**: Handle imbalanced defect types\n",
    "\n",
    "### Key Takeaways:\n",
    "- üéì **Spatial structure matters** for image classification\n",
    "- üèóÔ∏è **Architecture choice** depends on your constraints\n",
    "- üîÑ **Transfer learning** is powerful even for specialized domains\n",
    "- üìà **Progressive complexity** helps understand what each component adds\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Exercises for Further Exploration\n",
    "\n",
    "1. **Data Augmentation**: Add random rotations and noise during training\n",
    "2. **Attention Mechanisms**: Add attention layers to CNN\n",
    "3. **Model Ensemble**: Combine predictions from multiple models\n",
    "4. **Explainability**: Visualize CNN filters and activation maps\n",
    "5. **Different Architectures**: Try VGG, DenseNet, or EfficientNet\n",
    "6. **Class Imbalance**: Implement weighted loss or SMOTE\n",
    "7. **Hyperparameter Optimization**: Use Optuna or Ray Tune\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- PyTorch Documentation: https://pytorch.org/docs/\n",
    "- CNN Explainer: https://poloclub.github.io/cnn-explainer/\n",
    "- Transfer Learning Guide: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "- Papers with Code: https://paperswithcode.com/\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** üéâ You've completed the neural network development tutorial and learned how to progressively build and improve models for image classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
