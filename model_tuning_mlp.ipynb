{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from data_loading import WaferDataLoader\n",
    "from utility import (setup_model_and_loaders, hyperparameter_tuning, \n",
    "                     evaluate_model, train_model)\n",
    "from models import MLP\n",
    "from config import MLP_TUNING_GRID\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"✓ All libraries imported successfully!\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272c862",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2074e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using WaferDataLoader\n",
    "print(\"Loading wafer defect dataset...\")\n",
    "loader = WaferDataLoader()\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully!\")\n",
    "print(f\"X shape: {loader.X.shape}\")\n",
    "print(f\"y shape: {loader.y.shape}\")\n",
    "print(f\"Number of classes: {loader.num_classes}\")\n",
    "\n",
    "# Get the data\n",
    "X = loader.X.astype('float32')\n",
    "y = loader.y\n",
    "\n",
    "# Normalize data\n",
    "X_min, X_max = X.min(), X.max()\n",
    "X_normalized = (X - X_min) / (X_max - X_min) if X_max > X_min else X\n",
    "\n",
    "print(f\"\\n✓ Normalization:\")\n",
    "print(f\"  Original range: [{X_min}, {X_max}]\")\n",
    "print(f\"  Normalized range: [{X_normalized.min():.4f}, {X_normalized.max():.4f}]\")\n",
    "\n",
    "# Split into train/val/test (70% / 15% / 15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_normalized, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Data split complete:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(y)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(y)*100:.1f}%)\")\n",
    "print(f\"  Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a2db6",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display tuning grid\n",
    "print(\"=\"*80)\n",
    "print(\"MLP - HYPERPARAMETER TUNING GRID\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTuning Grid:\")\n",
    "for param, values in MLP_TUNING_GRID.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in MLP_TUNING_GRID.values()])\n",
    "print(f\"\\nTotal combinations to evaluate: {total_combinations}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b160f",
   "metadata": {},
   "source": [
    "## 3. Run Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Hyperparameter Tuning\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING HYPERPARAMETER TUNING\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_results = hyperparameter_tuning(\n",
    "    MLP, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "    param_grid=MLP_TUNING_GRID,\n",
    "    input_size=2704,\n",
    "    num_classes=38,\n",
    "    device=str(device),\n",
    "    num_epochs=25,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNING COMPLETE\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract top 5\n",
    "mlp_top5 = mlp_results['summary_df'].head(5).copy()\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(mlp_top5[['learning_rate', 'batch_size', 'hidden_sizes', 'dropout', 'num_epochs', 'optimizer', 'Val_Acc', 'Test_Acc']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58e8cd",
   "metadata": {},
   "source": [
    "## 4. Validation Loss Curves - Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain top 5 models to get training histories\n",
    "print(\"\\nRetraining top 5 models to generate loss curves...\")\n",
    "\n",
    "def retrain_with_history(model_class, X_train, X_val, X_test, y_train, y_val, y_test, \n",
    "                         params, input_size, num_classes, device_str):\n",
    "    \"\"\"Retrain a model with given params and return training history\"\"\"\n",
    "    try:\n",
    "        # Extract parameters\n",
    "        learning_rate = params.get('learning_rate', 0.001)\n",
    "        batch_size = params.get('batch_size', 64)\n",
    "        optimizer_type = params.get('optimizer', 'adam')\n",
    "        epochs_to_train = params.get('num_epochs', 20)\n",
    "        \n",
    "        # Build model_kwargs for architecture parameters\n",
    "        model_kwargs = {}\n",
    "        if 'hidden_sizes' in params:\n",
    "            hidden_sizes = params['hidden_sizes']\n",
    "            if isinstance(hidden_sizes, str):\n",
    "                hidden_sizes = hidden_sizes.strip('[]').split(',')\n",
    "                hidden_sizes = [int(h.strip()) for h in hidden_sizes]\n",
    "            model_kwargs['hidden_sizes'] = hidden_sizes\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model_kwargs['dropout'] = params['dropout']\n",
    "        \n",
    "        # Setup model and loaders\n",
    "        setup_result = setup_model_and_loaders(\n",
    "            model_class, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "            input_size=input_size, num_classes=num_classes, device=device_str,\n",
    "            batch_size=batch_size, model_kwargs=model_kwargs, verbose=False\n",
    "        )\n",
    "        \n",
    "        model = setup_result['model']\n",
    "        train_loader = setup_result['train_loader']\n",
    "        val_loader = setup_result['val_loader']\n",
    "        \n",
    "        # Setup optimizer\n",
    "        if optimizer_type.lower() == 'adam':\n",
    "            opt = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            opt = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        \n",
    "        # Train\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        history = train_model(\n",
    "            model, train_loader, val_loader, criterion, opt,\n",
    "            num_epochs=epochs_to_train, device=device_str, patience=5\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get histories for top 5\n",
    "top5_histories = []\n",
    "for i, (_, row) in enumerate(mlp_top5.iterrows(), 1):\n",
    "    print(f\"  Retraining rank {i}/5...\")\n",
    "    \n",
    "    # Extract parameters from row\n",
    "    params = {\n",
    "        'learning_rate': row['learning_rate'],\n",
    "        'batch_size': int(row['batch_size']),\n",
    "        'optimizer': row['optimizer'],\n",
    "        'num_epochs': int(row['num_epochs']),\n",
    "        'hidden_sizes': row['hidden_sizes'],\n",
    "        'dropout': row['dropout'],\n",
    "    }\n",
    "    \n",
    "    history = retrain_with_history(\n",
    "        MLP, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "        params, input_size=2704, num_classes=38, device_str=str(device)\n",
    "    )\n",
    "    if history:\n",
    "        top5_histories.append(history)\n",
    "\n",
    "print(f\"✓ Successfully generated {len(top5_histories)} training histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss curves for top 5\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Multi-Layer Perceptron - Top 5 Configurations\\nTraining vs Validation Loss', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, history in enumerate(top5_histories):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "    ax.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "    \n",
    "    rank = idx + 1\n",
    "    val_acc = mlp_top5.iloc[idx]['Val_Acc']\n",
    "    ax.set_title(f'Rank {rank} - Val Acc: {val_acc:.4f}', fontweight='bold', fontsize=11)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[1, 2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlp_validation_loss_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Loss curves plot saved as 'mlp_validation_loss_curves.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841bb98",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = 'mlp_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save summary CSV with all results\n",
    "mlp_results['summary_df'].to_csv(f'{results_dir}/all_results_{timestamp}.csv', index=False)\n",
    "print(f\"✓ All results saved to: all_results_{timestamp}.csv\")\n",
    "\n",
    "# 2. Save top 5 CSV\n",
    "mlp_top5.to_csv(f'{results_dir}/top5_results_{timestamp}.csv', index=False)\n",
    "print(f\"✓ Top 5 results saved to: top5_results_{timestamp}.csv\")\n",
    "\n",
    "# 3. Save best model info\n",
    "best_model_info = {\n",
    "    'best_params': mlp_results['best_params'],\n",
    "    'best_val_acc': float(mlp_results['best_val_acc']),\n",
    "    'best_test_acc': float(mlp_results['best_test_acc']),\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/best_model_{timestamp}.json', 'w') as f:\n",
    "    json.dump(best_model_info, f, indent=4, default=str)\n",
    "print(f\"✓ Best model info saved to: best_model_{timestamp}.json\")\n",
    "\n",
    "# 4. Save best model itself\n",
    "torch.save(mlp_results['best_model'].state_dict(), \n",
    "           f'{results_dir}/best_model_weights_{timestamp}.pt')\n",
    "print(f\"✓ Best model weights saved to: best_model_weights_{timestamp}.pt\")\n",
    "\n",
    "# 5. Save training history for best model\n",
    "with open(f'{results_dir}/best_model_history_{timestamp}.pkl', 'wb') as f:\n",
    "    pickle.dump(mlp_results['best_history'], f)\n",
    "print(f\"✓ Best model training history saved to: best_model_history_{timestamp}.pkl\")\n",
    "\n",
    "# 6. Save training histories for top 5\n",
    "for i, history in enumerate(top5_histories, 1):\n",
    "    with open(f'{results_dir}/rank_{i:02d}_history_{timestamp}.pkl', 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "print(f\"✓ Top 5 training histories saved\")\n",
    "\n",
    "# 7. Save loss curves data as CSV for easy access\n",
    "for i, history in enumerate(top5_histories, 1):\n",
    "    loss_df = pd.DataFrame({\n",
    "        'Epoch': range(1, len(history['train_loss']) + 1),\n",
    "        'Train_Loss': history['train_loss'],\n",
    "        'Val_Loss': history['val_loss'],\n",
    "        'Train_Acc': history['train_acc'],\n",
    "        'Val_Acc': history['val_acc'],\n",
    "    })\n",
    "    loss_df.to_csv(f'{results_dir}/rank_{i:02d}_loss_curves_{timestamp}.csv', index=False)\n",
    "print(f\"✓ Loss curves data saved as CSV for all top 5\")\n",
    "\n",
    "# 8. Save summary report\n",
    "summary = {\n",
    "    'model': 'MLP',\n",
    "    'timestamp': timestamp,\n",
    "    'total_combinations': int(total_combinations),\n",
    "    'best_val_accuracy': float(mlp_results['best_val_acc']),\n",
    "    'best_test_accuracy': float(mlp_results['best_test_acc']),\n",
    "    'best_hyperparameters': mlp_results['best_params'],\n",
    "    'top5_accuracies': mlp_top5['Val_Acc'].tolist(),\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/summary_report_{timestamp}.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=4, default=str)\n",
    "print(f\"✓ Summary report saved to: summary_report_{timestamp}.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"All results saved to: {results_dir}/\".center(80))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5bbf2",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-LAYER PERCEPTRON - TUNING RESULTS SUMMARY\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBest Model Performance:\")\n",
    "print(f\"  Validation Accuracy: {mlp_results['best_val_acc']:.4f}\")\n",
    "print(f\"  Test Accuracy: {mlp_results['best_test_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "for key, value in mlp_results['best_params'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nTop 5 Validation Accuracies:\")\n",
    "for rank, acc in enumerate(mlp_top5['Val_Acc'].values, 1):\n",
    "    print(f\"  Rank {rank}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal tuning combinations evaluated: {total_combinations}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
