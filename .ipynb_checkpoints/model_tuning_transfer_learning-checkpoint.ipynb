{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f23551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n",
      "âœ“ All libraries imported successfully!\n",
      "Device: cuda\n",
      "\n",
      "âœ“ Using ResNet18 for Transfer Learning with layer freezing options\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules (force reload)\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Clear any cached imports\n",
    "if 'models' in sys.modules:\n",
    "    del sys.modules['models']\n",
    "if 'data_loading' in sys.modules:\n",
    "    del sys.modules['data_loading']\n",
    "if 'utility' in sys.modules:\n",
    "    del sys.modules['utility']\n",
    "if 'config' in sys.modules:\n",
    "    del sys.modules['config']\n",
    "\n",
    "from data_loading import WaferDataLoader\n",
    "from utility import (setup_model_and_loaders, hyperparameter_tuning, \n",
    "                     evaluate_model, train_model)\n",
    "from models import WaferResNet18  # Changed from WaferMobileNet to WaferResNet18\n",
    "from config import TRANSFER_LEARNING_TUNING_GRID\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"\\nâœ“ Using ResNet18 for Transfer Learning with layer freezing options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf031a",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d22348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wafer defect dataset...\n",
      "Loading dataset from kagglehub cache...\n",
      "âœ“ Dataset loaded successfully\n",
      "  Wafer maps shape: (38015, 52, 52)\n",
      "  Raw labels shape: (38015, 8)\n",
      "âœ“ Labels converted to class indices\n",
      "  Number of unique defect classes: 38\n",
      "âœ“ Dataset loaded successfully!\n",
      "X shape: (38015, 52, 52)\n",
      "y shape: (38015,)\n",
      "Number of classes: 38\n",
      "\n",
      "âœ“ Normalization:\n",
      "  Original range: [0.0, 3.0]\n",
      "  Normalized range: [0.0000, 1.0000]\n",
      "\n",
      "âœ“ Reshaped for ResNet18: (38015, 3, 52, 52)\n",
      "\n",
      "âœ“ Data split complete (using SUBSETS for faster training):\n",
      "  Training set: 10000 samples (subset from 26610)\n",
      "  Validation set: 3000 samples (subset from 5702)\n",
      "  Test set: 5703 samples (FULL - for accurate evaluation)\n",
      "\n",
      "âš¡ Training speedup: ~2.7x faster\n"
     ]
    }
   ],
   "source": [
    "# Load data using WaferDataLoader\n",
    "print(\"Loading wafer defect dataset...\")\n",
    "loader = WaferDataLoader()\n",
    "\n",
    "print(f\"âœ“ Dataset loaded successfully!\")\n",
    "print(f\"X shape: {loader.X.shape}\")\n",
    "print(f\"y shape: {loader.y.shape}\")\n",
    "print(f\"Number of classes: {loader.num_classes}\")\n",
    "\n",
    "# Get the data\n",
    "X = loader.X.astype('float32')\n",
    "y = loader.y\n",
    "\n",
    "# Normalize data\n",
    "X_min, X_max = X.min(), X.max()\n",
    "X_normalized = (X - X_min) / (X_max - X_min) if X_max > X_min else X\n",
    "\n",
    "print(f\"\\nâœ“ Normalization:\")\n",
    "print(f\"  Original range: [{X_min}, {X_max}]\")\n",
    "print(f\"  Normalized range: [{X_normalized.min():.4f}, {X_normalized.max():.4f}]\")\n",
    "\n",
    "# Reshape to 2D image format: (N, 2704) -> (N, 52, 52)\n",
    "X_normalized = X_normalized.reshape(-1, 52, 52)\n",
    "\n",
    "# Expand to 3 channels for ResNet18: (N, 52, 52) -> (N, 3, 52, 52)\n",
    "# Replicate grayscale across 3 channels\n",
    "X_normalized = np.repeat(X_normalized[:, np.newaxis, :, :], 3, axis=1)\n",
    "print(f\"\\nâœ“ Reshaped for ResNet18: {X_normalized.shape}\")\n",
    "\n",
    "# Split into train/val/test (70% / 15% / 15%)\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X_normalized, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val_full, X_test, y_val_full, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# USE SUBSET FOR FASTER TRAINING (adjust these values as needed)\n",
    "# ============================================================================\n",
    "TRAIN_SUBSET_SIZE = 10000   # Use 5000 training samples (out of ~26k)\n",
    "VAL_SUBSET_SIZE = 3000     # Use 1500 validation samples (out of ~5.7k)\n",
    "# Test set remains full for accurate evaluation\n",
    "\n",
    "# Stratified sampling to maintain class distribution\n",
    "from sklearn.model_selection import train_test_split as stratified_sample\n",
    "\n",
    "if TRAIN_SUBSET_SIZE < len(y_train_full):\n",
    "    X_train, _, y_train, _ = stratified_sample(\n",
    "        X_train_full, y_train_full, \n",
    "        train_size=TRAIN_SUBSET_SIZE, \n",
    "        random_state=42, \n",
    "        stratify=y_train_full\n",
    "    )\n",
    "else:\n",
    "    X_train, y_train = X_train_full, y_train_full\n",
    "\n",
    "if VAL_SUBSET_SIZE < len(y_val_full):\n",
    "    X_val, _, y_val, _ = stratified_sample(\n",
    "        X_val_full, y_val_full, \n",
    "        train_size=VAL_SUBSET_SIZE, \n",
    "        random_state=42, \n",
    "        stratify=y_val_full\n",
    "    )\n",
    "else:\n",
    "    X_val, y_val = X_val_full, y_val_full\n",
    "\n",
    "print(f\"\\nâœ“ Data split complete (using SUBSETS for faster training):\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples (subset from {len(y_train_full)})\")\n",
    "print(f\"  Validation set: {X_val.shape[0]} samples (subset from {len(y_val_full)})\")\n",
    "print(f\"  Test set: {X_test.shape[0]} samples (FULL - for accurate evaluation)\")\n",
    "print(f\"\\nâš¡ Training speedup: ~{len(y_train_full)/len(y_train):.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bfbde",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628ffd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "           TRANSFER LEARNING (ResNet18) - HYPERPARAMETER TUNING GRID            \n",
      "================================================================================\n",
      "\n",
      "Tuning Grid:\n",
      "  learning_rate: [0.001, 0.0001]\n",
      "  batch_size: [32]\n",
      "  num_epochs: [20]\n",
      "  freeze_layers: [4]\n",
      "  dropout: [0.3]\n",
      "\n",
      "ðŸ“Œ freeze_layers explanation:\n",
      "  0 = Train all layers (fine-tune entire network)\n",
      "  2 = Freeze layer1 + layer2 (train layer3, layer4, and classifier)\n",
      "  4 = Freeze all conv layers (only train classifier - fastest)\n",
      "\n",
      "Total combinations to evaluate: 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display tuning grid\n",
    "print(\"=\"*80)\n",
    "print(\"TRANSFER LEARNING (ResNet18) - HYPERPARAMETER TUNING GRID\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTuning Grid:\")\n",
    "for param, values in TRANSFER_LEARNING_TUNING_GRID.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Explain freeze_layers parameter\n",
    "print(f\"\\nðŸ“Œ freeze_layers explanation:\")\n",
    "print(f\"  0 = Train all layers (fine-tune entire network)\")\n",
    "print(f\"  2 = Freeze layer1 + layer2 (train layer3, layer4, and classifier)\")\n",
    "print(f\"  4 = Freeze all conv layers (only train classifier - fastest)\")\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in TRANSFER_LEARNING_TUNING_GRID.values()])\n",
    "print(f\"\\nTotal combinations to evaluate: {total_combinations}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a31d4",
   "metadata": {},
   "source": [
    "## 3. Run Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f490459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYPERPARAMETER TUNING: Transfer Learning (ResNet18)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š ResNet18 Architecture Info:\n",
      "  Total parameters: 11,196,006\n",
      "  freeze_layers=0: 11,196,006 trainable (100.0%)\n",
      "  freeze_layers=2: 10,512,934 trainable (93.9%)\n",
      "  freeze_layers=4: 19,494 trainable (0.2%)\n",
      "\n",
      "âœ“ Starting hyperparameter tuning...\n",
      "  Total combinations: 2\n",
      "\n",
      "======================================================================\n",
      "                  HYPERPARAMETER TUNING: Grid Search                  \n",
      "======================================================================\n",
      "Model: WaferResNet18\n",
      "Total combinations to evaluate: 2\n",
      "Parameters: learning_rate, batch_size, num_epochs, freeze_layers, dropout\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/2] Testing: {'learning_rate': 0.001, 'batch_size': 32, 'num_epochs': 20, 'freeze_layers': 4, 'dropout': 0.3}\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Train Loss: 3.1631, Train Acc: 0.1908\n",
      "  Val Loss: 2.0900, Val Acc: 0.3467\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:\n",
      "  Train Loss: 2.3139, Train Acc: 0.3044\n",
      "  Val Loss: 1.8736, Val Acc: 0.3960\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:\n",
      "  Train Loss: 2.1987, Train Acc: 0.3246\n",
      "  Val Loss: 1.8404, Val Acc: 0.3930\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:\n",
      "  Train Loss: 2.1378, Train Acc: 0.3432\n",
      "  Val Loss: 1.8067, Val Acc: 0.4053\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20:\n",
      "  Train Loss: 2.0949, Train Acc: 0.3484\n",
      "  Val Loss: 1.7800, Val Acc: 0.4117\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:\n",
      "  Train Loss: 2.0867, Train Acc: 0.3567\n",
      "  Val Loss: 1.7866, Val Acc: 0.4143\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:\n",
      "  Train Loss: 2.0571, Train Acc: 0.3592\n",
      "  Val Loss: 1.7369, Val Acc: 0.4273\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20:\n",
      "  Train Loss: 2.0758, Train Acc: 0.3594\n",
      "  Val Loss: 1.7629, Val Acc: 0.4267\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20:\n",
      "  Train Loss: 2.1028, Train Acc: 0.3542\n",
      "  Val Loss: 1.7549, Val Acc: 0.4223\n",
      "  Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20:\n",
      "  Train Loss: 2.0659, Train Acc: 0.3670\n",
      "  Val Loss: 1.7361, Val Acc: 0.4250\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20:\n",
      "  Train Loss: 2.0688, Train Acc: 0.3597\n",
      "  Val Loss: 1.7369, Val Acc: 0.4277\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:\n",
      "  Train Loss: 2.0898, Train Acc: 0.3628\n",
      "  Val Loss: 1.7347, Val Acc: 0.4230\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20:\n",
      "  Train Loss: 2.0712, Train Acc: 0.3673\n",
      "  Val Loss: 1.7306, Val Acc: 0.4347\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20:\n",
      "  Train Loss: 2.0640, Train Acc: 0.3620\n",
      "  Val Loss: 1.7300, Val Acc: 0.4250\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20:\n",
      "  Train Loss: 2.0704, Train Acc: 0.3612\n",
      "  Val Loss: 1.7312, Val Acc: 0.4210\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20:\n",
      "  Train Loss: 2.0749, Train Acc: 0.3630\n",
      "  Val Loss: 1.7241, Val Acc: 0.4333\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20:\n",
      "  Train Loss: 2.0617, Train Acc: 0.3627\n",
      "  Val Loss: 1.7208, Val Acc: 0.4367\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:\n",
      "  Train Loss: 2.0700, Train Acc: 0.3620\n",
      "  Val Loss: 1.7227, Val Acc: 0.4317\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:\n",
      "  Train Loss: 2.0936, Train Acc: 0.3639\n",
      "  Val Loss: 1.7470, Val Acc: 0.4210\n",
      "  Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:\n",
      "  Train Loss: 2.0677, Train Acc: 0.3660\n",
      "  Val Loss: 1.7274, Val Acc: 0.4360\n",
      "  Patience: 3/5\n",
      "\n",
      "Loaded best model with validation loss: 1.7208\n",
      "Train Acc: 0.3660 | Val Acc: 0.4360 | Test Acc: 0.4126\n",
      "âœ“ NEW BEST! (Val Acc: 0.4360)\n",
      "\n",
      "[2/2] Testing: {'learning_rate': 0.0001, 'batch_size': 32, 'num_epochs': 20, 'freeze_layers': 4, 'dropout': 0.3}\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Train Loss: 5.4871, Train Acc: 0.0418\n",
      "  Val Loss: 3.6231, Val Acc: 0.1070\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:\n",
      "  Train Loss: 3.6552, Train Acc: 0.1015\n",
      "  Val Loss: 3.0259, Val Acc: 0.1930\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:\n",
      "  Train Loss: 3.1871, Train Acc: 0.1608\n",
      "  Val Loss: 2.7119, Val Acc: 0.2527\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:\n",
      "  Train Loss: 2.9250, Train Acc: 0.1940\n",
      "  Val Loss: 2.5002, Val Acc: 0.2880\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20:\n",
      "  Train Loss: 2.7342, Train Acc: 0.2254\n",
      "  Val Loss: 2.3594, Val Acc: 0.3190\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:\n",
      "  Train Loss: 2.6023, Train Acc: 0.2399\n",
      "  Val Loss: 2.2683, Val Acc: 0.3227\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:\n",
      "  Train Loss: 2.5039, Train Acc: 0.2699\n",
      "  Val Loss: 2.1623, Val Acc: 0.3540\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20:\n",
      "  Train Loss: 2.4153, Train Acc: 0.2785\n",
      "  Val Loss: 2.1083, Val Acc: 0.3660\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20:\n",
      "  Train Loss: 2.3358, Train Acc: 0.2958\n",
      "  Val Loss: 2.0481, Val Acc: 0.3790\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20:\n",
      "  Train Loss: 2.2777, Train Acc: 0.3052\n",
      "  Val Loss: 2.0291, Val Acc: 0.3793\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20:\n",
      "  Train Loss: 2.2373, Train Acc: 0.3202\n",
      "  Val Loss: 1.9853, Val Acc: 0.3927\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:\n",
      "  Train Loss: 2.1990, Train Acc: 0.3239\n",
      "  Val Loss: 1.9503, Val Acc: 0.4013\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20:\n",
      "  Train Loss: 2.1558, Train Acc: 0.3329\n",
      "  Val Loss: 1.9162, Val Acc: 0.4097\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20:\n",
      "  Train Loss: 2.1244, Train Acc: 0.3432\n",
      "  Val Loss: 1.9162, Val Acc: 0.4157\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20:\n",
      "  Train Loss: 2.0966, Train Acc: 0.3554\n",
      "  Val Loss: 1.8812, Val Acc: 0.4163\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20:\n",
      "  Train Loss: 2.0704, Train Acc: 0.3634\n",
      "  Val Loss: 1.8701, Val Acc: 0.4113\n",
      "  âœ“ New best validation loss!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20:\n",
      "  Train Loss: 2.0492, Train Acc: 0.3664\n",
      "  Val Loss: 1.8701, Val Acc: 0.4220\n",
      "  Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ“ Starting hyperparameter tuning...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total combinations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.prod([\u001b[38;5;28mlen\u001b[39m(v)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mTRANSFER_LEARNING_TUNING_GRID.values()])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m tl_results = \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWaferResNet18\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRANSFER_LEARNING_TUNING_GRID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Extract results dataframe and get top 5\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tl_results[\u001b[33m'\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/rmirandaquintana/ak.surendran/ChemEngg/Wafer-defect-ECH6845/utility.py:947\u001b[39m, in \u001b[36mhyperparameter_tuning\u001b[39m\u001b[34m(model_class, X_train, X_val, X_test, y_train, y_val, y_test, param_grid, input_size, num_classes, device, criterion, num_epochs, patience, verbose)\u001b[39m\n\u001b[32m    944\u001b[39m     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\u001b[32m    946\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs_to_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[32m    953\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/rmirandaquintana/ak.surendran/ChemEngg/Wafer-defect-ECH6845/utility.py:59\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, patience)\u001b[39m\n\u001b[32m     56\u001b[39m loss.backward()\n\u001b[32m     57\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * inputs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     60\u001b[39m _, predicted = torch.max(outputs, \u001b[32m1\u001b[39m)\n\u001b[32m     61\u001b[39m train_total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Transfer Learning with ResNet18\n",
    "print(\"=\" * 80)\n",
    "print(\"HYPERPARAMETER TUNING: Transfer Learning (ResNet18)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show model architecture info\n",
    "print(\"\\nðŸ“Š ResNet18 Architecture Info:\")\n",
    "test_model = WaferResNet18(num_classes=38, freeze_layers=0)\n",
    "info = test_model.get_frozen_info()\n",
    "print(f\"  Total parameters: {info['total_params']:,}\")\n",
    "\n",
    "for fl in [0, 2, 4]:\n",
    "    test_model = WaferResNet18(num_classes=38, freeze_layers=fl)\n",
    "    info = test_model.get_frozen_info()\n",
    "    print(f\"  freeze_layers={fl}: {info['trainable_params']:,} trainable ({info['trainable_percent']:.1f}%)\")\n",
    "del test_model\n",
    "\n",
    "print(\"\\nâœ“ Starting hyperparameter tuning...\")\n",
    "print(f\"  Total combinations: {np.prod([len(v) for v in TRANSFER_LEARNING_TUNING_GRID.values()])}\")\n",
    "\n",
    "tl_results = hyperparameter_tuning(\n",
    "    model_class=WaferResNet18,\n",
    "    X_train=X_train,\n",
    "    X_val=X_val,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    "    y_test=y_test,\n",
    "    param_grid=TRANSFER_LEARNING_TUNING_GRID,\n",
    "    input_size=None,\n",
    "    num_classes=loader.num_classes,\n",
    "    device=str(device),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Extract results dataframe and get top 5\n",
    "if tl_results['best_params'] is not None:\n",
    "    print(f\"\\nâœ“ Tuning complete! Tested {len(tl_results['results'])} hyperparameter combinations\")\n",
    "    tl_summary_df = tl_results['summary_df']\n",
    "    tl_top5 = tl_summary_df.head(min(5, len(tl_summary_df)))\n",
    "\n",
    "    print(f\"\\nTop {len(tl_top5)} Best Results:\")\n",
    "    display_cols = ['learning_rate', 'batch_size', 'num_epochs', 'freeze_layers', 'dropout', 'Val_Acc', 'Test_Acc']\n",
    "    display_cols = [c for c in display_cols if c in tl_top5.columns]\n",
    "    print(tl_top5[display_cols].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nâœ“ Best Model Performance:\")\n",
    "    print(f\"  Validation Accuracy: {tl_results['best_val_acc']:.4f}\")\n",
    "    print(f\"  Test Accuracy: {tl_results['best_test_acc']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nERROR: All hyperparameter combinations failed!\")\n",
    "    if tl_results['results']:\n",
    "        print(f\"First result: {tl_results['results'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b593ad0",
   "metadata": {},
   "source": [
    "## 4. Validation Loss Curves - Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain top 5 models to get training histories\n",
    "print(\"\\nRetraining top 5 models to generate loss curves...\")\n",
    "\n",
    "def retrain_with_history(model_class, X_train, X_val, X_test, y_train, y_val, y_test, \n",
    "                         params, num_classes, device_str):\n",
    "    \"\"\"Retrain a model with given params and return training history\"\"\"\n",
    "    try:\n",
    "        # Extract parameters from params dict\n",
    "        learning_rate = params.get('learning_rate', 0.0001)\n",
    "        batch_size = int(params.get('batch_size', 32))\n",
    "        epochs_to_train = int(params.get('num_epochs', 20))\n",
    "        freeze_layers = int(params.get('freeze_layers', 0))\n",
    "        dropout = params.get('dropout', 0.5)\n",
    "        \n",
    "        # Model kwargs for ResNet18\n",
    "        model_kwargs = {\n",
    "            'freeze_layers': freeze_layers,\n",
    "            'dropout': dropout\n",
    "        }\n",
    "        \n",
    "        # Setup model and loaders\n",
    "        setup_result = setup_model_and_loaders(\n",
    "            model_class, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "            input_size=None, num_classes=num_classes, device=device_str,\n",
    "            batch_size=batch_size, model_kwargs=model_kwargs, verbose=False\n",
    "        )\n",
    "        \n",
    "        model = setup_result['model']\n",
    "        train_loader = setup_result['train_loader']\n",
    "        val_loader = setup_result['val_loader']\n",
    "        \n",
    "        # Setup optimizer - only optimize trainable parameters\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        opt = optim.Adam(trainable_params, lr=learning_rate)\n",
    "        \n",
    "        # Train\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        history = train_model(\n",
    "            model, train_loader, val_loader, criterion, opt,\n",
    "            num_epochs=epochs_to_train, device=device_str, patience=5\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Get histories for top 5\n",
    "top5_histories = []\n",
    "for i, (idx, row) in enumerate(tl_top5.iterrows(), 1):\n",
    "    print(f\"  Retraining rank {i}/5...\")\n",
    "    \n",
    "    # Extract parameters from row\n",
    "    params = {\n",
    "        'learning_rate': float(row['learning_rate']),\n",
    "        'batch_size': int(row['batch_size']),\n",
    "        'num_epochs': int(row['num_epochs']),\n",
    "    }\n",
    "    # Add freeze_layers and dropout if available\n",
    "    if 'freeze_layers' in row:\n",
    "        params['freeze_layers'] = int(row['freeze_layers'])\n",
    "    if 'dropout' in row:\n",
    "        params['dropout'] = float(row['dropout'])\n",
    "    \n",
    "    history = retrain_with_history(\n",
    "        WaferResNet18, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "        params, num_classes=loader.num_classes, device_str=str(device)\n",
    "    )\n",
    "    if history:\n",
    "        top5_histories.append(history)\n",
    "\n",
    "print(f\"âœ“ Successfully generated {len(top5_histories)} training histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss curves for top 5\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Transfer Learning (ResNet18) - Top 5 Configurations\\nTraining vs Validation Loss', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, history in enumerate(top5_histories):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "    ax.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "    \n",
    "    rank = idx + 1\n",
    "    val_acc = tl_top5.iloc[idx]['Val_Acc']\n",
    "    freeze_info = f\", freeze={int(tl_top5.iloc[idx]['freeze_layers'])}\" if 'freeze_layers' in tl_top5.columns else \"\"\n",
    "    ax.set_title(f'Rank {rank} - Val Acc: {val_acc:.4f}{freeze_info}', fontweight='bold', fontsize=11)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[1, 2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('transfer_learning_resnet18_validation_loss_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Loss curves plot saved as 'transfer_learning_resnet18_validation_loss_curves.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406d2ef",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = 'transfer_learning_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save summary CSV with all results\n",
    "tl_summary_df.to_csv(f'{results_dir}/all_results_{timestamp}.csv', index=False)\n",
    "print(f\"âœ“ All results saved to: all_results_{timestamp}.csv\")\n",
    "\n",
    "# 2. Save top 5 CSV\n",
    "tl_top5.to_csv(f'{results_dir}/top5_results_{timestamp}.csv', index=False)\n",
    "print(f\"âœ“ Top 5 results saved to: top5_results_{timestamp}.csv\")\n",
    "\n",
    "# 3. Save best model info\n",
    "best_model_info = {\n",
    "    'model_architecture': 'ResNet18',\n",
    "    'best_params': tl_results['best_params'],\n",
    "    'best_val_acc': float(tl_results['best_val_acc']),\n",
    "    'best_test_acc': float(tl_results['best_test_acc']),\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/best_model_{timestamp}.json', 'w') as f:\n",
    "    json.dump(best_model_info, f, indent=4, default=str)\n",
    "print(f\"âœ“ Best model info saved to: best_model_{timestamp}.json\")\n",
    "\n",
    "# 4. Save best model itself\n",
    "torch.save(tl_results['best_model'].state_dict(), \n",
    "           f'{results_dir}/best_model_weights_{timestamp}.pt')\n",
    "print(f\"âœ“ Best model weights saved to: best_model_weights_{timestamp}.pt\")\n",
    "\n",
    "# 5. Save training history for best model\n",
    "with open(f'{results_dir}/best_model_history_{timestamp}.pkl', 'wb') as f:\n",
    "    pickle.dump(tl_results['best_history'], f)\n",
    "print(f\"âœ“ Best model training history saved to: best_model_history_{timestamp}.pkl\")\n",
    "\n",
    "# 6. Save training histories for top 5\n",
    "for i, history in enumerate(top5_histories, 1):\n",
    "    with open(f'{results_dir}/rank_{i:02d}_history_{timestamp}.pkl', 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "print(f\"âœ“ Top 5 training histories saved\")\n",
    "\n",
    "# 7. Save loss curves data as CSV for easy access\n",
    "for i, history in enumerate(top5_histories, 1):\n",
    "    loss_df = pd.DataFrame({\n",
    "        'Epoch': range(1, len(history['train_loss']) + 1),\n",
    "        'Train_Loss': history['train_loss'],\n",
    "        'Val_Loss': history['val_loss'],\n",
    "        'Train_Acc': history['train_acc'],\n",
    "        'Val_Acc': history['val_acc'],\n",
    "    })\n",
    "    loss_df.to_csv(f'{results_dir}/rank_{i:02d}_loss_curves_{timestamp}.csv', index=False)\n",
    "print(f\"âœ“ Loss curves data saved as CSV for all top 5\")\n",
    "\n",
    "# 8. Save summary report\n",
    "total_combinations = len(tl_results['results'])\n",
    "summary = {\n",
    "    'model': 'Transfer Learning (ResNet18)',\n",
    "    'timestamp': timestamp,\n",
    "    'total_combinations': int(total_combinations),\n",
    "    'best_val_accuracy': float(tl_results['best_val_acc']),\n",
    "    'best_test_accuracy': float(tl_results['best_test_acc']),\n",
    "    'best_hyperparameters': tl_results['best_params'],\n",
    "    'top5_accuracies': tl_top5['Val_Acc'].tolist(),\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/summary_report_{timestamp}.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=4, default=str)\n",
    "print(f\"âœ“ Summary report saved to: summary_report_{timestamp}.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"All results saved to: {results_dir}/\".center(80))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ed6cc",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4503e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFER LEARNING (ResNet18) - TUNING RESULTS SUMMARY\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBest Model Performance:\")\n",
    "print(f\"  Validation Accuracy: {tl_results['best_val_acc']:.4f}\")\n",
    "print(f\"  Test Accuracy: {tl_results['best_test_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "for key, value in tl_results['best_params'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Show frozen layer info for best model\n",
    "best_freeze = tl_results['best_params'].get('freeze_layers', 0)\n",
    "print(f\"\\nðŸ“Œ Layer Freezing Strategy:\")\n",
    "if best_freeze == 0:\n",
    "    print(f\"  All layers are trainable (full fine-tuning)\")\n",
    "elif best_freeze == 4:\n",
    "    print(f\"  All conv layers frozen (only classifier trained)\")\n",
    "else:\n",
    "    print(f\"  First {best_freeze} residual blocks frozen\")\n",
    "\n",
    "print(f\"\\nTop 5 Validation Accuracies:\")\n",
    "for rank, (_, row) in enumerate(tl_top5.iterrows(), 1):\n",
    "    acc = row['Val_Acc']\n",
    "    freeze = int(row['freeze_layers']) if 'freeze_layers' in row else 'N/A'\n",
    "    print(f\"  Rank {rank}: {acc:.4f} (freeze_layers={freeze})\")\n",
    "\n",
    "total_combinations = len(tl_results['results'])\n",
    "print(f\"\\nTotal tuning combinations evaluated: {total_combinations}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a007c",
   "metadata": {},
   "source": [
    "## 7. Best Model Evaluation - Classification Report & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb93a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from datetime import datetime\n",
    "\n",
    "# Load best model and generate predictions\n",
    "best_model = tl_results['best_model']\n",
    "best_model.eval()\n",
    "\n",
    "# Debug: Check X_test shape\n",
    "print(f\"Original X_test shape: {X_test.shape}\")\n",
    "\n",
    "# X_test is already 3-channel from preprocessing: (N, 3, 52, 52)\n",
    "# No need to convert - use directly\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "print(f\"X_test_tensor shape for ResNet18: {X_test_tensor.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = best_model(X_test_tensor)\n",
    "    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Generate classification report\n",
    "class_names = [f'Class_{i:02d}' for i in range(38)]\n",
    "report = classification_report(y_test, predictions, target_names=class_names, digits=4)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT - ResNet18 Transfer Learning BEST MODEL (All 38 Classes)\")\n",
    "print(\"=\"*80)\n",
    "print(report)\n",
    "\n",
    "# Save classification report\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_path = f'classification_report_resnet18_{timestamp}.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"CLASSIFICATION REPORT - ResNet18 Transfer Learning BEST MODEL (All 38 Classes)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(report)\n",
    "print(f\"\\nâœ“ Classification report saved to: {report_path}\")\n",
    "\n",
    "# Compute and visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(f\"\\nConfusion Matrix Shape: {cm.shape}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax, \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Confusion Matrix - ResNet18 Transfer Learning Best Model (38Ã—38)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = f'confusion_matrix_resnet18_{timestamp}.png'\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Confusion matrix saved to: {cm_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Extract per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, predictions, labels=range(38))\n",
    "class_accuracy = recall  # Recall is per-class accuracy\n",
    "\n",
    "# Create metrics dataframe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support,\n",
    "    'Accuracy': class_accuracy\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS METRICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Save per-class metrics\n",
    "metrics_path = f'class_wise_metrics_resnet18_{timestamp}.csv'\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"\\nâœ“ Per-class metrics saved to: {metrics_path}\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n",
    "print(f\"Macro-Average Precision: {precision.mean():.4f}\")\n",
    "print(f\"Macro-Average Recall: {recall.mean():.4f}\")\n",
    "print(f\"Macro-Average F1-Score: {f1.mean():.4f}\")\n",
    "print(f\"\\nBest Performing Classes (Top 5 by F1-Score):\")\n",
    "top_5 = metrics_df.nlargest(5, 'F1-Score')[['Class', 'F1-Score', 'Recall', 'Support']]\n",
    "print(top_5.to_string(index=False))\n",
    "print(f\"\\nWorst Performing Classes (Bottom 5 by F1-Score):\")\n",
    "bottom_5 = metrics_df.nsmallest(5, 'F1-Score')[['Class', 'F1-Score', 'Recall', 'Support']]\n",
    "print(bottom_5.to_string(index=False))\n",
    "\n",
    "# Create comprehensive 4-subplot visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Subplot 1: Per-class Accuracy (Recall) with color coding\n",
    "ax1 = axes[0, 0]\n",
    "colors_acc = ['green' if x >= 0.8 else 'orange' if x >= 0.6 else 'red' for x in class_accuracy]\n",
    "bars1 = ax1.bar(range(38), class_accuracy, color=colors_acc, edgecolor='black', linewidth=0.5)\n",
    "ax1.axhline(y=class_accuracy.mean(), color='blue', linestyle='--', linewidth=2, label=f'Mean: {class_accuracy.mean():.3f}')\n",
    "ax1.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy (Recall)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Per-Class Accuracy Distribution', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(range(0, 38, 2))\n",
    "ax1.set_xticklabels([f'C{i}' for i in range(0, 38, 2)], fontsize=9)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Subplot 2: Precision vs Recall Scatter\n",
    "ax2 = axes[0, 1]\n",
    "colors_pr = ['green' if x >= 0.8 else 'orange' if x >= 0.6 else 'red' for x in class_accuracy]\n",
    "scatter = ax2.scatter(recall, precision, c=colors_pr, s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Perfect Performance')\n",
    "ax2.set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Precision vs Recall (Per-Class)', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlim([-0.05, 1.05])\n",
    "ax2.set_ylim([-0.05, 1.05])\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Subplot 3: F1-Score by Class\n",
    "ax3 = axes[1, 0]\n",
    "colors_f1 = ['green' if x >= 0.8 else 'orange' if x >= 0.6 else 'red' for x in f1]\n",
    "bars3 = ax3.bar(range(38), f1, color=colors_f1, edgecolor='black', linewidth=0.5)\n",
    "ax3.axhline(y=f1.mean(), color='blue', linestyle='--', linewidth=2, label=f'Mean: {f1.mean():.3f}')\n",
    "ax3.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('F1-Score Distribution by Class', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks(range(0, 38, 2))\n",
    "ax3.set_xticklabels([f'C{i}' for i in range(0, 38, 2)], fontsize=9)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Subplot 4: Support Distribution (Sample Count)\n",
    "ax4 = axes[1, 1]\n",
    "bars4 = ax4.bar(range(38), support, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "ax4.axhline(y=support.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {support.mean():.0f}')\n",
    "ax4.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Class Distribution in Test Set (Support)', fontsize=13, fontweight='bold')\n",
    "ax4.set_xticks(range(0, 38, 2))\n",
    "ax4.set_xticklabels([f'C{i}' for i in range(0, 38, 2)], fontsize=9)\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "accuracy_path = f'class_wise_accuracy_resnet18_{timestamp}.png'\n",
    "plt.savefig(accuracy_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Class-wise accuracy visualization saved to: {accuracy_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETE - All results saved successfully\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Wafer Defect)",
   "language": "python",
   "name": "wafer_defect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
